{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff260e7-fe3c-4bfd-bb2a-99f0c2e9a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from mtcnn.mtcnn import MTCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a79166c-06e4-4f24-a28a-1647405eef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2189 images belonging to 3 classes.\n",
      "Found 822 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Preprocessing the Training set\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\nehan\\Documents\\Mega_Sync\\VJTI\\Sum_Pro\\Face_Det_Keras\\face_dataset\\train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "\n",
    "# Preprocessing the Test set\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\nehan\\Documents\\Mega_Sync\\VJTI\\Sum_Pro\\Face_Det_Keras\\face_dataset\\test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "                                    \n",
    "classifier = load_model('theoff_keras_2_Con_layers.hdf5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e795224d-d7c4-403b-801a-5bf3109bfc15",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\nehan\\\\Documents\\\\Mega_Sync\\\\VJTI\\\\Sum_Pro\\\\VGG16\\\\face_dataset\\\\test\\\\Steve Carell\\\\sc_te (1).jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae594d2ba7bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnew_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'sc_te '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'('\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m')'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Facdet\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    290\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m   \"\"\"\n\u001b[1;32m--> 292\u001b[1;33m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[0;32m    293\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Facdet\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\nehan\\\\Documents\\\\Mega_Sync\\\\VJTI\\\\Sum_Pro\\\\VGG16\\\\face_dataset\\\\test\\\\Steve Carell\\\\sc_te (1).jpg'"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\nehan\\Documents\\Mega_Sync\\VJTI\\Sum_Pro\\VGG16\\face_dataset\\test\\Steve Carell'\n",
    "count_rainn = 0\n",
    "count_john = 0\n",
    "count_steve = 0\n",
    "\n",
    "for i in range(1,229):\n",
    "    new_path = path + '\\\\' + 'sc_te ' + '(' + str(i) + ')' + '.jpg'\n",
    "    pred = []\n",
    "    test_image = image.load_img(new_path, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    var = result.argmax(axis = -1)\n",
    "    #print(training_set.class_indices)\n",
    "    if result[0][0] == 1:\n",
    "        pred.append('John Krasinski')\n",
    "        count_john = count_john + 1\n",
    "    elif result[0][1] == 1:\n",
    "        pred.append('Rainn Wilson')\n",
    "        count_rainn = count_rainn + 1\n",
    "    elif result[0][2] == 1:\n",
    "        pred.append('Steve Carell')\n",
    "        count_steve = count_steve + 1\n",
    "\n",
    "print('Rainn')\n",
    "print(count_rainn)\n",
    "\n",
    "print('Steve')\n",
    "print(count_steve)\n",
    "\n",
    "print('John')\n",
    "print(count_john)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d126bcb2-f2b3-4da4-8852-956a4f94886e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\nehan\\\\Documents\\\\Mega_Sync\\\\VJTI\\\\Sum_Pro\\\\VGG16\\\\test_images\\\\jkm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f8f8bf54ff30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcount_steve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_im_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_im_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\nehan\\\\Documents\\\\Mega_Sync\\\\VJTI\\\\Sum_Pro\\\\VGG16\\\\test_images\\\\jkm'"
     ]
    }
   ],
   "source": [
    "test_im_path = r'C:\\Users\\nehan\\Documents\\Mega_Sync\\VJTI\\Sum_Pro\\VGG16\\test_images\\jkm'\n",
    "pred = []\n",
    "count_rainn = 0\n",
    "count_john = 0\n",
    "count_steve = 0\n",
    "    \n",
    "for filename in os.listdir(test_im_path):\n",
    "    file_path = os.path.join(test_im_path,filename)\n",
    "    im = cv2.imread(file_path)\n",
    "    detector = MTCNN()\n",
    "    det_face = detector.detect_faces(im)\n",
    "    \n",
    "    for f in det_face:\n",
    "        x, y, w, h = f['box']\n",
    "        test_face = im[y:y + h, x:x + w]\n",
    "        test_face = Image.fromarray(test_face)\n",
    "        test_face = test_face.resize((64,64))\n",
    "        #test_image = image.load_img(test_face, target_size = (64, 64))\n",
    "        test_image = image.img_to_array(test_face)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = classifier.predict(test_image)\n",
    "        var = result.argmax(axis = -1)\n",
    "        #print(training_set.class_indices)\n",
    "        if result[0][0] == 1:\n",
    "            pred.append('John Krasinski')\n",
    "            count_john = count_john + 1\n",
    "        elif result[0][1] == 1:\n",
    "            pred.append('Rainn Wilson')\n",
    "            count_rainn = count_rainn + 1\n",
    "        elif result[0][2] == 1:\n",
    "            pred.append('Steve Carell')\n",
    "            count_steve = count_steve + 1\n",
    "\n",
    "print('Rainn')\n",
    "print(count_rainn)\n",
    "\n",
    "print('Steve')\n",
    "print(count_steve)\n",
    "\n",
    "print('John')\n",
    "print(count_john)\n",
    "\n",
    "#         cv2.imshow('Faces', test_face) \n",
    "#         cv2.waitKey(500)\n",
    "            \n",
    "      \n",
    "        #image = cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 255), thickness=2)\n",
    "        \n",
    "\n",
    "            #cv2.imwrite(new_name,face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3809c530-36eb-40fe-983c-7009f0f481e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000241F65A30D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000241F6E159D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Frame 85 / 574 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tile cannot extend outside image",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d81ca3eaf22c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'box'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtest_face\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mtest_face\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_face\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mtest_face\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_face\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m#test_image = image.load_img(test_face, target_size = (64, 64))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Facdet\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2791\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2793\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Facdet\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2731\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2733\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Facdet\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2678\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2679\u001b[1;33m     \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2680\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Facdet\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[1;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;31m# unpack data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_getdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m         \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: tile cannot extend outside image"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(r'C:\\Users\\nehan\\Documents\\Mega_Sync\\VJTI\\Sum_Pro\\Face_Det_Keras/19secs.mp4')\n",
    "length = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_movie = cv2.VideoWriter('19secs.avi', fourcc, 30, (1920, 1080))\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    ret,frame = vid.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "#     gpu_frame = cv2.cuda_GpuMat()\n",
    "    \n",
    "#     gpu_frame.upload(frame)\n",
    "    \n",
    "#     frame = gpu_frame.download()\n",
    "    detector = MTCNN()\n",
    "        # This internal method detects faces in the video feed\n",
    "    detected_faces = detector.detect_faces(frame)\n",
    "\n",
    "    if ret != []:\n",
    "        for face in detected_faces:\n",
    "            x,y,w,h = face['box']\n",
    "            test_face = frame[y:y + h, x:x + w]\n",
    "            test_face = Image.fromarray(test_face)\n",
    "            test_face = test_face.resize((64,64))\n",
    "            #test_image = image.load_img(test_face, target_size = (64, 64))\n",
    "            test_image = image.img_to_array(test_face)\n",
    "            test_image = np.expand_dims(test_image, axis = 0)\n",
    "            result = classifier.predict(test_image)\n",
    "            var = result.argmax(axis = -1)\n",
    "            #print(training_set.class_indices)\n",
    "            if result[0][0] == 1:\n",
    "                prediction = 'John Krasinski'\n",
    "            elif result[0][1] == 1:\n",
    "                prediction = 'Rainn Wilson'\n",
    "            elif result[0][2] == 1:\n",
    "                prediction = 'Steve Carell'\n",
    "            \n",
    "            name = prediction\n",
    "            \n",
    "            # Trace the rectangle encasing the faces \n",
    "            cv2.rectangle(frame,(x, y),\n",
    "                              (x + w,\n",
    "                               y + h),(0,155,255),2)\n",
    "            \n",
    "            cv2.putText(frame, name, (x, y), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show the tracing in the video feed\n",
    "            #cv2.imshow('frame',frame)\n",
    "            print(\"Frame {} / {} \".format(i,length))\n",
    "            output_movie.write(frame)\n",
    "            \n",
    "            #Stop the video capture if 'q' is pressed\n",
    "            if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    i = i+1\n",
    "    \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391bab20-0a5a-4cb7-80e8-aa611f4778ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width, height: 1920.0 1080.0\n",
      "fps: 30.0\n",
      "frames count: 574.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "#vcap = cv2.VideoCapture(0)  # built-in webcamera\n",
    "\n",
    "vcap = cv2.VideoCapture('19secs.mp4')\n",
    "\n",
    "if vcap.isOpened(): \n",
    "    # width  = vcap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "    # height = vcap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "    # or\n",
    "    width  = vcap.get(3)  # float `width`\n",
    "    height = vcap.get(4)  # float `height`\n",
    "\n",
    "    print('width, height:', width, height)\n",
    "    \n",
    "    # fps = vcap.get(cv2.CAP_PROP_FPS)\n",
    "    # or\n",
    "    fps = vcap.get(5)\n",
    "    \n",
    "    print('fps:', fps)  # float `fps`\n",
    "    \n",
    "    # frame_count = vcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    # or\n",
    "    frame_count = vcap.get(7)\n",
    "    \n",
    "    print('frames count:', frame_count)  # float `frame_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6b5e0-7bd1-434b-b40e-90d2940ed82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
